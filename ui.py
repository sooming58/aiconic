# app.py
import streamlit as st
from streamlit.components.v1 import html
from cryptography.fernet import Fernet
from reportlab.lib.pagesizes import A4
from reportlab.pdfgen import canvas
from io import BytesIO
from streamlit_webrtc import webrtc_streamer, WebRtcMode, WebRtcStreamerContext
from aiortc.contrib.media import MediaRecorder
import soundfile as sf
from pathlib import Path
import time
import pydub
import whisper

st.set_page_config(page_title="Accessible Voiceâ†’PDF", layout="centered")

# --- Audio recording setup (from audio_new.py) ---
TMP_DIR = Path("C:/audio/sound")
if not TMP_DIR.exists():
    TMP_DIR.mkdir(exist_ok=True, parents=True)

if "wavpath" not in st.session_state:
    cur_time = time.strftime("%Y-%m-%d_%H-%M-%S", time.localtime())
    st.session_state["wavpath"] = str(TMP_DIR / f"{cur_time}.wav")

wavpath = st.session_state["wavpath"]

# ì˜¤ë””ì˜¤ ì…ë ¥ ì„¤ì •
MEDIA_STREAM_CONSTRAINTS = {
    "video": False,
    "audio": {
        "echoCancellation": False,
        "noiseSuppression": True,
        "autoGainControl": True,
    },
}

# ì˜¤ë””ì˜¤ í”„ë ˆì„ ìˆ˜ì§‘ -> pydubìœ¼ë¡œ ì €ì¥
def save_frames_from_audio_receiver(wavpath):
    webrtc_ctx = webrtc_streamer(
        key = "sendonly-audio",
        mode = WebRtcMode.SENDONLY,
        media_stream_constraints=MEDIA_STREAM_CONSTRAINTS,
    )

    if "audio_buffer" not in st.session_state:
        st.session_state["audio_buffer"] = pydub.AudioSegment.empty()

    while True:
        if webrtc_ctx.audio_receiver:
            audio_frames = webrtc_ctx.audio_receiver.get_frames(timeout=1)
            for audio_frame in audio_frames:
                sound = pydub.AudioSegment(
                    data=audio_frame.to_ndarray().tobytes(),
                    sample_width=audio_frame.format.bytes,
                    frame_rate=audio_frame.sample_rate,
                    channels=len(audio_frame.layout.channels),
                )
                st.session_state["audio_buffer"] += sound
        else:
            break

    # ë…¹ìŒì´ ëë‚˜ë©´ ë²„í¼ë¥¼ WAVë¡œ ì €ì¥
    audio_buffer = st.session_state["audio_buffer"]
    if not webrtc_ctx.state.playing and len(audio_buffer) > 0:
        audio_buffer.export(wavpath, format="wav")
        st.session_state["audio_buffer"] = pydub.AudioSegment.empty()

# ì €ì¥ëœ wav íŒŒì¼ ì¬ìƒ
def display_wavfile(wavpath):
    audio_bytes = open(wavpath, 'rb').read()
    file_type = Path(wavpath).suffix
    st.audio(audio_bytes, format=f'audio/{file_type}', start_time=0)

# --- Styles for big buttons, high contrast, accessible fonts ---
st.markdown(
    """
    <style>
    .big-btn { font-size:20px; padding:18px 24px; border-radius:12px; }
    .high-contrast { background-color:#0B5FFF; color: #FFFFFF; }
    .container { max-width:900px; margin: 0 auto; }
    label[for="template_select"] { font-weight:700; }
    .sr-only { position: absolute; left: -10000px; top: auto; width: 1px; height: 1px; overflow: hidden; }
    </style>
    """,
    unsafe_allow_html=True,
)

st.markdown("# ì‹œê°ì¥ì• ì¸ì„ ìœ„í•œ ìŒì„± ê¸°ë°˜ ê°œì¸ì •ë³´ ì…ë ¥ ë° ì„œë¥˜ ìë™ ì‘ì„± ì„œë¹„ìŠ¤")
st.markdown(
    "ìŒì„± ì…ë ¥ â†’ í…ìŠ¤íŠ¸ í™•ì¸ â†’ í…ìŠ¤íŠ¸ ì•”í˜¸í™”(ì„ íƒ) â†’ í…œí”Œë¦¿ ì„ íƒ â†’ PDF ìƒì„±\n\n"
    "**ì„¤ëª…:** í° ë²„íŠ¼, ìƒ‰ìƒ ëŒ€ë¹„, ìŠ¤í¬ë¦°ë¦¬ë”(aria) ì§€ì›, ìŒì„± ì•ˆë‚´ í¬í•¨."
)

# --- Voice recorder & speech-to-text (WebRTC + Whisper) ---
st.markdown("## 1. ìŒì„± ì…ë ¥ (WebRTC ë…¹ìŒ + Whisper ë³€í™˜)")

# ë…¹ìŒ ì„¹ì…˜
st.markdown("### ì˜¤ë””ì˜¤ ë…¹ìŒ")
save_frames_from_audio_receiver(wavpath)

# ë…¹ìŒëœ íŒŒì¼ì´ ìˆìœ¼ë©´ ì¬ìƒ
if Path(wavpath).exists():
    st.markdown(f"**ë…¹ìŒ íŒŒì¼:** {wavpath}")
    display_wavfile(wavpath)
    
    # Whisper ë³€í™˜ ë²„íŠ¼
    col1, col2 = st.columns([1, 1])
    with col1:
        if st.button("ğŸ¤ Whisperë¡œ í…ìŠ¤íŠ¸ ë³€í™˜", key="whisper_convert", help="ë…¹ìŒëœ ì˜¤ë””ì˜¤ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."):
            with st.spinner("Whisper ëª¨ë¸ ë¡œë”© ë° ë³€í™˜ ì¤‘..."):
                try:
                    model = whisper.load_model("small")
                    result = model.transcribe(str(wavpath))
                    transcribed_text = result["text"]
                    st.session_state["voice_text"] = transcribed_text
                    st.success("âœ… ë³€í™˜ ì™„ë£Œ")
                except Exception as e:
                    st.error(f"âŒ ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    with col2:
        if st.button("ğŸ”„ ë…¹ìŒ ì´ˆê¸°í™”", key="reset_recording", help="ë…¹ìŒì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."):
            if "audio_buffer" in st.session_state:
                st.session_state["audio_buffer"] = pydub.AudioSegment.empty()
            cur_time = time.strftime("%Y-%m-%d_%H-%M-%S", time.localtime())
            st.session_state["wavpath"] = str(TMP_DIR / f"{cur_time}.wav")
            st.rerun()

# ìŒì„±ì—ì„œ ê°€ì ¸ì˜¨ í…ìŠ¤íŠ¸ í‘œì‹œ
st.markdown("### ìŒì„±ì—ì„œ ê°€ì ¸ì˜¨ í…ìŠ¤íŠ¸")
if st.session_state.get("voice_text"):
    st.text_area("Recognized text (from voice)", value=st.session_state.get("voice_text", ""), key="voice_text", height=140, label_visibility="collapsed")
else:
    st.text_area("Recognized text (from voice)", value="", key="voice_text", height=140, label_visibility="collapsed",
                 help="ìœ„ì˜ ë…¹ìŒ í›„ 'Whisperë¡œ í…ìŠ¤íŠ¸ ë³€í™˜' ë²„íŠ¼ì„ ëˆ„ë¥´ê±°ë‚˜ ì§ì ‘ ì…ë ¥í•˜ì„¸ìš”.")

# --- Encryption section ---
st.markdown("## 2. í…ìŠ¤íŠ¸ ì•”í˜¸í™” (ì„ íƒ)")
encrypt = st.checkbox("í…ìŠ¤íŠ¸ ì•”í˜¸í™” ì‚¬ìš©í•˜ê¸°", value=False)
password_key = None
encrypted_text = None

if encrypt:
    # Generate key from passphrase (simple). For production, use proper KDF (PBKDF2HMAC) with salt.
    passphrase = st.text_input("ì•”í˜¸(ë³µí˜¸í™” ì‹œ í•„ìš”)", type="password", help="ë³µí˜¸í™”í•˜ë ¤ë©´ ë™ì¼í•œ ì•”í˜¸ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")
    if passphrase:
        # derive a fernet key (NOTE: simplified; production => use PBKDF2HMAC+salt)
        import base64, hashlib
        k = hashlib.sha256(passphrase.encode()).digest()
        key = base64.urlsafe_b64encode(k)
        f = Fernet(key)
        raw = st.session_state.get("voice_text", "")
        if raw:
            if st.button("ì•”í˜¸í™”", key="encrypt_btn"):
                token = f.encrypt(raw.encode())
                encrypted_text = token.decode()
                st.success("ì•”í˜¸í™” ì™„ë£Œ. ë³µí˜¸í™”í•˜ë ¤ë©´ ê°™ì€ ì•”í˜¸ ì‚¬ìš©.")
                st.code(encrypted_text, language=None)
        else:
            st.info("ë¨¼ì € í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥/ì „ì†¡í•˜ì„¸ìš”.")
else:
    st.info("ì•”í˜¸í™”ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë©´ ì›ë¬¸ì´ PDFë¡œ ì €ì¥ë©ë‹ˆë‹¤.")

# allow manual editing of final text to be put into PDF
st.markdown("## 3. ìµœì¢… í…ìŠ¤íŠ¸ (PDFë¡œ ìƒì„±ë  ë‚´ìš©)")
final_text = st.text_area("Final text (editable)", value=(encrypted_text or st.session_state.get("voice_text","")), height=200)

# --- Template selection ---
st.markdown("## 4. í…œí”Œë¦¿ ì„ íƒ")
template = st.selectbox("í…œí”Œë¦¿ì„ ì„ íƒí•˜ì„¸ìš”", options=["Simple (íƒ€ì´í‹€+ë³¸ë¬¸)","Letter (í¸ì§€í˜•)","Report (ë³´ê³ ì„œí˜•)"], key="template_select")

# Accessibility hint for screen readers
st.markdown('<div role="note" aria-live="polite">í…œí”Œë¦¿ì„ ì„ íƒí•œ ë’¤ PDF ìƒì„± ë²„íŠ¼ì„ ëˆ„ë¥´ì„¸ìš”.</div>', unsafe_allow_html=True)

# --- PDF generation ---
st.markdown("## 5. PDF ìƒì„±")
col1, col2 = st.columns([1,1])
with col1:
    if st.button("PDF ìƒì„±", key="generate_pdf", help="ì„ íƒëœ í…œí”Œë¦¿ìœ¼ë¡œ PDFë¥¼ ë§Œë“­ë‹ˆë‹¤.",):
        # build PDF in memory
        buffer = BytesIO()
        c = canvas.Canvas(buffer, pagesize=A4)
        width, height = A4
        margin = 50
        title = "Generated Document"
        if template == "Simple (íƒ€ì´í‹€+ë³¸ë¬¸)":
            c.setFont("Helvetica-Bold", 20)
            c.drawString(margin, height - margin - 10, title)
            c.setFont("Helvetica", 12)
            text_obj = c.beginText(margin, height - margin - 40)
            for line in final_text.splitlines():
                text_obj.textLine(line)
            c.drawText(text_obj)
        elif template == "Letter (í¸ì§€í˜•)":
            c.setFont("Helvetica", 12)
            text_obj = c.beginText(margin, height - margin - 10)
            text_obj.textLine("To whom it may concern,")
            text_obj.textLine("")
            for line in final_text.splitlines():
                text_obj.textLine(line)
            text_obj.textLine("")
            text_obj.textLine("Sincerely,")
            text_obj.textLine("Streamlit User")
            c.drawText(text_obj)
        else:  # Report
            c.setFont("Helvetica-Bold", 18)
            c.drawCentredString(width/2, height - margin, "REPORT")
            c.setFont("Helvetica", 11)
            text_obj = c.beginText(margin, height - margin - 40)
            for line in final_text.splitlines():
                text_obj.textLine(line)
            c.drawText(text_obj)

        c.showPage()
        c.save()
        buffer.seek(0)
        st.session_state["last_pdf"] = buffer.read()
        st.success("PDF ìƒì„± ì™„ë£Œ.")
with col2:
    if st.session_state.get("last_pdf", None):
        st.download_button("PDF ë‹¤ìš´ë¡œë“œ", data=st.session_state["last_pdf"], file_name="document.pdf", mime="application/pdf", key="dl_pdf",)
    else:
        st.info("PDFë¥¼ ë¨¼ì € ìƒì„±í•˜ì„¸ìš”.")